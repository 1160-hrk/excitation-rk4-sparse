# C++多準位系ベンチマーク結果とJuliaとの比較

## 実行環境
- **C++**: Linux 6.10.14-linuxkit (ARM64), OpenMP 14スレッド
- **Julia**: Docker環境, BLAS 7スレッド
- **共通設定**: 
  - 全体時間: 10.0
  - 時間刻み: 0.01
  - ステップ数: 500 (実際の計算ステップ数)
  - 電場振幅: 1.0
  - 電場周波数: 1.0

## ベンチマーク結果比較

### C++ Sparse Matrix vs Julia Sparse Matrix

| 次元 | C++ (ms) | Julia (ms) | 高速化比 (Julia/C++) | C++ スケーリング | Julia スケーリング |
|------|----------|------------|---------------------|------------------|-------------------|
| 2    | 0.086    | 0.100      | 1.16x               | -                | -                 |
| 4    | 0.088    | 0.113      | 1.28x               | -                | -                 |
| 8    | 0.165    | 0.131      | 0.79x               | 1.9x slower      | 1.2x slower       |
| 16   | 0.214    | 0.169      | 0.79x               | 1.3x slower      | 1.3x slower       |
| 32   | 0.331    | 0.266      | 0.80x               | 1.5x slower      | 1.6x slower       |
| 64   | 0.646    | 0.490      | 0.76x               | 2.0x slower      | 1.8x slower       |
| 128  | 1.288    | 1.017      | 0.79x               | 2.0x slower      | 2.1x slower       |
| 256  | 2.557    | 1.656      | 0.65x               | 2.0x slower      | 1.6x slower       |
| 512  | 6.036    | 2.367      | 0.39x               | 2.4x slower      | 1.4x slower       |
| 1024 | 12.810   | 4.807      | 0.38x               | 2.1x slower      | 2.0x slower       |

## スケーリング解析

### C++ Sparse Matrix
- **実行時間スケーリング**: O(dim^0.83)
- **フィッティング式**: time = 0.028 × dim^0.83

### Julia Sparse Matrix（参考）
- **実行時間スケーリング**: O(dim^0.65)
- **フィッティング式**: time = 0.039 × dim^0.65

## 詳細分析

### 小次元 (2-32)
- **C++の優位性**: 小次元ではC++がわずかに高速（1.16x-1.28x）
- **理由**: C++のコンパイル時最適化の効果
- **JuliaのVMオーバーヘッド**: 小規模計算でのインタープリタ的オーバーヘッド

### 中次元 (64-256)
- **Julia優位に転換**: Juliaが1.3x-1.5x高速
- **理由**: JuliaのBLAS最適化が効果を発揮
- **C++の課題**: 効率的なBLAS利用の不足

### 大次元 (512-1024)
- **Juliaの圧倒的優位**: Juliaが2.5x-3.4x高速
- **スケーリング差**: Julia O(dim^0.65) vs C++ O(dim^0.83)
- **C++の性能劣化**: 次元増加に対する性能劣化が顕著

## 結論

### C++実装の特徴
**利点**:
- 小次元での低オーバーヘッド
- 予測可能な性能特性
- ネイティブコンパイルによる最適化

**課題**:
- 大次元でのスケーリング性能
- BLAS/LAPACK最適化の活用不足
- 並列化戦略の改善余地

### 推奨事項
1. **BLAS最適化**: OpenBLAS/MKLとの統合強化
2. **並列化改善**: OpenMPの効果的な活用
3. **メモリアクセス最適化**: キャッシュ効率の向上
4. **アルゴリズム改良**: Juliaのベストプラクティスの採用

### 用途別推奨
- **小次元 (≤32)**: C++でも十分な性能
- **中次元 (64-256)**: Juliaが推奨、ただしC++も実用的
- **大次元 (≥512)**: Juliaを強く推奨

## 次のステップ
1. 密行列実装の安定化とベンチマーク追加
2. BLAS最適化実装の修正と検証
3. 並列化戦略の見直し
4. メモリ効率の改善

---
*注: このベンチマークは特定の環境・設定での結果であり、実際の性能は使用環境やデータの特性により変動する可能性があります。* 